# OpenSSF CVE Benchmark for AI

README of the original repo can be found [here](https://github.com/ossf-cve-benchmark/ossf-cve-benchmark).

# About

This enhanced version of the benchmark addresses the problem that function level AI models face when they try to use
the original benchmark: function level alerts. The original benchmark is designed to compare tools that produce alerts
at the line level, but some AI models produce alerts at the function level. This enhanced version of the benchmark is
designed to compare tools that produce alerts at the line OR function level.

## Using the CVE Benchmark

### Step 1: install the tooling and metadata
Simply clone this repo and use `npm` to set up the tooling (requires npm &GreaterEqual; 7 and Node.js &GreaterEqual; 12):

```
$ git clone git@github.com:ossf-cve-benchmark/ossf-cve-benchmark.git
$ cd ossf-cve-benchmark
$ npm i
$ npm run-script build
```

### Step 2: run the security tools against the benchmark

The tooling included in the OpenSSF CVE Benchmark will help you evaluate the ability of security tools to generate alerts for the vulnerabilities (CVEs) in the dataset. The benchmark tooling will run the security tools on the source code of the commits associated with CVEs. Using the tools' output, you can then generate benchmark reports that show how the security tools performed. 
For more information about generating benchmark reports, see 
[Step 3](#step-3-generate-benchmark-reports) below.

Before running an analysis, you must install the security tools you wish to benchmark and configure the *tool drivers* accordingly.
A tool driver is a script that acts as the interface
between the analysis tools and the CVE Benchmark.
For reference information about analysis tool drivers, including information 
about adding drivers for new tools, see 
[Analysis tools](docs/analysis-tools.md). 
To see how to set up ESLint to run an analysis, see 
[Generating a benchmark report for `eslint`](docs/eslint-example.md)

To run an analysis, use the `bin/cli run` command 
specifying:

- the identifier of the driver for your analysis tool, 
  as given in [`config.json`](docs/configuration.md), using the `--tool` option. 
- one or more CVEs to run the analysis on. For more information, 
  see [Selecting CVEs of interest](docs/configuration.md#selecting-cves-of-interest).

For example, to run an analysis using ESLint over CVE-2018-16492 
and CVE-2020-4066 you would use:

```
$ bin/cli run --tool eslint-default CVE-2018-16492 CVE-2020-4066
```

where `eslint-default` is the name of the driver configured for ESLint
analysis in the `config.json` file:

```json
{
  "tools": {
    "eslint-default": {
      "bin": "node",
      "args": [
        "/home/user-name/ossf-cve-benchmark/build/ts/contrib/tools/eslint/src/eslint.js"
      ],
      "options": {
        "eslintDir": "/home/user-name/analysis-tools/eslint-2020-12-08"
      }
    }
  }
}
```

To run ESLint against all CVEs in the dataset, you can run:

```
$ bin/cli run --tool eslint-default '*'
```

### Step 3: generate benchmark reports

After running one or more security tools against the dataset (using `bin/cli run`), you can generate benchmark reports to see how well different security tools performed at detecting vulnerabilities. To do this, you can run `bin/cli` with the `report` command, which can generate either an [interactive browser-based report](#interactive-report-in-your-web-browser), or a [text-based report](#text-based-reporting).

#### Interactive report in your web browser

To view an interactive benchmark report in your browser, you can use the `report` command with the `--kind server` option. Just like the `run` command, it expects you to specify one or more CVEs. You can also pass it `'*'` to generate a report for all CVEs in the dataset. 

For example, to browse a report that compares ESLint to NodeJSScan on all CVEs in the dataset, you would use:

```
$ bin/cli report --kind server --tool eslint-default --tool nodejsscan '*'
```

After running this command, you can browse the report at http://localhost:8080.

There are some special ways to [select groups of CVEs](docs/configuration.md#selecting-cves-of-interest). For example, if you're interested in a report for *just* [MITRE's Top-25 CWEs](https://cwe.mitre.org/top25/archive/2020/2020_cwe_top25.html), you could run:

```
$ bin/cli report --kind server --tool eslint-default --tool nodejsscan mitre-cwe-top:25:2020
```

#### Text-based reporting
Use `--kind txt` to create a static text-based report. For example:

```
$ bin/cli report --kind txt --tool eslint-default CVE-2018-16492 CVE-2020-4066
```

## Status and roadmap

This project has only just started and we'd love your help! The CVE Benchmark currently supports benchmarking
three JavaScript security analysis tools on just over 200 CVEs. 

In time, we'll work on the following high-level improvements:

- additional CVE data, for both JavaScript and other languages
- support for additional security analysis tools, for both JavaScript and other languages
- more advanced reports

At the meta-level, we expect to soon formalize versioning
and release strategies, and to make the workflows for external
contributions as seamless as possible.

### We don't aim to be ...

- A way of organising and presenting data on all CVEs in existence (such as https://cve.mitre.org)
  - rather, this project hopes that the information in this project makes its way to such views
- A code viewer for browsing alerts (such as a [SARIF viewer](https://sarifweb.azurewebsites.net/#viewersSectionTitle))
  - rather, this project aims to have a simple analysis result format in order to have a low bar of entry for new analysis tools
- A platform for disclosing new security vulnerabilities (such as https://www.hackerone.com)
  - rather, this project contains simple descriptions of the weaknesses of the above vulnerabilities


We do :heart: all of the initiatives mentioned above!


## Contributing to the project

We welcome contributions to the OpenSSF CVE Benchmark project.  If you want
to contribute, then please go ahead and open a pull request! See
additional details in our [contributing guidelines](CONTRIBUTING.md) and our [FAQ](docs/FAQ.md).

## About us: the OpenSSF Security Tooling working group

The OpenSSF CVE Benchmark project was initiated by the [OpenSSF](https://openssf.org/)'s [Security Tooling working group](https://github.com/ossf/wg-security-tooling). The working group contains a wide variety of members; some contribute independently, others join through their roles at organizations like Google, GitHub, Mozilla, Tencent, and OWASP. The working group typically meets (virtually) once every two week; [all are welcome](https://github.com/ossf/wg-security-tooling#meeting-times). 
